{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108b9159-17fc-4ab2-9976-479271cc242c",
   "metadata": {},
   "source": [
    "# ECG Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0357f57c-c710-4c51-9f1e-6d8af8d98b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "class Dataset_ECG(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 features='S', data_path='/tf/hsh/new_ecg/lead2',\n",
    "                 target='II', scale=True, timeenc=0, freq='s', percent=100,\n",
    "                 seasonal_patterns=None):\n",
    "        \n",
    "        self.seq_len = size\n",
    "        \n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.freq = freq\n",
    "        self.percent = percent\n",
    "        \n",
    "        self.data_x = []\n",
    "        self.data_y = []\n",
    "        self.test_data_x = []\n",
    "        self.test_data_y = []\n",
    "        self.val_data_x = []\n",
    "        self.val_data_y = []\n",
    "        self.root_path = root_path\n",
    "        self.data_path = os.listdir(root_path)\n",
    "        self.__read_data__()\n",
    "\n",
    "        self.enc_in = self.data_x.shape[-1] # 단변량이면 1\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        for i in self.data_path :\n",
    "            \n",
    "            df_raw = pd.read_csv(os.path.join(self.root_path,i), index_col=0)\n",
    "            \n",
    "            if self.features == 'M' or self.features == 'MS':\n",
    "                cols_data = df_raw.columns[1:]\n",
    "                df_data = df_raw[cols_data]\n",
    "            elif self.features == 'S':\n",
    "                df_data = df_raw[[self.target]]\n",
    "    \n",
    "            if self.scale:\n",
    "                train_data = df_data\n",
    "                self.scaler.fit(train_data.values)\n",
    "                data = self.scaler.transform(train_data.values)\n",
    "            else:\n",
    "                data = df_data.values\n",
    "    \n",
    "            df_stamp = df_raw.index\n",
    "            self.data_stamp = df_stamp.values\n",
    "            \n",
    "            if i[-5] == '1' or i[-5] == '0':\n",
    "                self.val_data_x.append(data)\n",
    "                \n",
    "                tmp_y = df_raw[['super_class']].iloc[0,0]\n",
    "                if tmp_y == 'NORM':\n",
    "                    self.val_data_y.append([1,0])\n",
    "                else:\n",
    "                    self.val_data_y.append([0,1])\n",
    "                    \n",
    "            elif i[-5] == '2' :\n",
    "                self.test_data_x.append(data)\n",
    "                \n",
    "                tmp_y = df_raw[['super_class']].iloc[0,0]\n",
    "                if tmp_y == 'NORM':\n",
    "                    self.test_data_y.append([1,0])\n",
    "                else:\n",
    "                    self.test_data_y.append([0,1])\n",
    "                \n",
    "            else :\n",
    "                self.data_x.append(data)\n",
    "                \n",
    "                tmp_y = df_raw[['super_class']].iloc[0,0]\n",
    "                if tmp_y == 'NORM':\n",
    "                    self.data_y.append([1,0])\n",
    "                else:\n",
    "                    self.data_y.append([0,1])\n",
    "            \n",
    "            \n",
    "        self.data_x = torch.tensor(self.data_x)\n",
    "        self.data_y = torch.tensor(self.data_y)\n",
    "\n",
    "        print(self.data_x.shape)\n",
    "        print(self.data_y.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_x[index].unsqueeze(0), self.data_y[index].unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_x.shape[0]\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d8ab41-666c-4607-8bd8-a50872d92c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14953, 2500, 1])\n",
      "torch.Size([14953, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_433594/3212616286.py:90: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  self.data_x = torch.tensor(self.data_x)\n"
     ]
    }
   ],
   "source": [
    "data_set = Dataset_ECG(root_path='/tf/hsh/new_ecg/lead2', data_path='', size=5000, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4075e4d8-bae1-44ae-a4b5-866795cc124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14953, 2500, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca76d8e-b0ed-474a-a9d0-cae8e400d392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        ...,\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14c323f-f509-410b-bac7-a5c75f8eac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0 days 00:00:00', '0 days 00:00:00.002000',\n",
       "       '0 days 00:00:00.004000', ..., '0 days 00:00:04.994000',\n",
       "       '0 days 00:00:04.996000', '0 days 00:00:04.998000'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.data_stamp # array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a54293a-5531-4a6f-a359-20a16b4511a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14953"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6dcbea-07c6-49da-b409-c1044503c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcf5d4b-a11d-4c66-b430-5779b79111a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset_ECG at 0x7f107126bb50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1af82ca7-83fb-4a16-a59c-29c9d86186e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n",
      "torch.Size([1, 1, 2500, 1])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x, batch_y) in enumerate(data_loader):\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616fd15-8a6f-4049-98fb-5e93822f864d",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b39d12-8866-46f9-b679-74f880b15620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Sequential(\n",
    "                        nn.Linear(nf, 512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(512, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, target_window)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(x) # 이진분류 아니면 softmax로 바꿔야 함\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b44952-6475-470e-9d76-05379d1ac653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class ReprogrammingLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_keys=None, d_llm=None, attention_dropout=0.1):\n",
    "        super(ReprogrammingLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.out_projection = nn.Linear(d_keys * n_heads, d_llm)\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, _ = target_embedding.shape \n",
    "        S, _ = source_embedding.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        target_embedding = self.query_projection(target_embedding).view(B, L, H, -1)\n",
    "        source_embedding = self.key_projection(source_embedding).view(S, H, -1)\n",
    "        value_embedding = self.value_projection(value_embedding).view(S, H, -1)\n",
    "\n",
    "        out = self.reprogramming(target_embedding, source_embedding, value_embedding)\n",
    "\n",
    "        out = out.reshape(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out)\n",
    "\n",
    "    def reprogramming(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, H, E = target_embedding.shape\n",
    "\n",
    "        scale = 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,she->bhls\", target_embedding, source_embedding)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        reprogramming_embedding = torch.einsum(\"bhls,she->blhe\", A, value_embedding)\n",
    "\n",
    "        return reprogramming_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda4762f-2adf-43af-8e37-e0417d4345e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from layers.StandardNorm import Normalize\n",
    "from transformers import LlamaConfig, LlamaModel, LlamaTokenizer\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.seq_len = 5000\n",
    "        self.llm_layers = 32\n",
    "        self.d_model = 32\n",
    "        self.d_ff = 128\n",
    "        self.d_llm = 4096\n",
    "        self.n_heads = 8\n",
    "        self.patch_len = 156\n",
    "        self.stride = 78\n",
    "        self.enc_in = 1\n",
    "        self.num_class = 2\n",
    "        self.dropout_rate = 0.1\n",
    "\n",
    "        # 모델 정의\n",
    "        \n",
    "        self.llama_config = LlamaConfig.from_pretrained('huggyllama/llama-7b')\n",
    "        self.llama_config.num_hidden_layers = self.llm_layers\n",
    "        self.llama_config.output_attentions = True\n",
    "        self.llama_config.output_hidden_states = True\n",
    "\n",
    "        self.llm_model = LlamaModel.from_pretrained(\n",
    "                        'huggyllama/llama-7b',\n",
    "                        trust_remote_code=True,\n",
    "                        local_files_only=True,\n",
    "                        config=self.llama_config,\n",
    "        )\n",
    "\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\n",
    "            'huggyllama/llama-7b',\n",
    "            trust_remote_code=True,\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        if self.tokenizer.eos_token:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        else:\n",
    "            pad_token = '[PAD]'\n",
    "            self.tokenizer.add_special_tokens({'pad_token': pad_token})\n",
    "            self.tokenizer.pad_token = pad_token\n",
    "\n",
    "        for param in self.llm_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # layer 정의\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        \n",
    "        self.patch_embedding = PatchEmbedding(\n",
    "            self.d_model, self.patch_len, self.stride, self.dropout_rate)\n",
    "\n",
    "        self.word_embeddings = self.llm_model.get_input_embeddings().weight\n",
    "        self.vocab_size = self.word_embeddings.shape[0]\n",
    "        self.num_tokens = 1000\n",
    "        self.mapping_layer = nn.Linear(self.vocab_size, self.num_tokens)\n",
    "\n",
    "        self.reprogramming_layer = ReprogrammingLayer(self.d_model, self.n_heads, self.d_ff, self.d_llm)\n",
    "\n",
    "        self.patch_nums = int((self.seq_len - self.patch_len) / self.stride + 2)\n",
    "        self.head_nf = self.d_ff * self.patch_nums\n",
    "\n",
    "        self.output_projection = FlattenHead(\n",
    "            self.enc_in, self.head_nf, self.num_class, head_dropout=self.dropout_rate)\n",
    "        \n",
    "        self.normalize_layers = Normalize(self.enc_in, affine=False)\n",
    "\n",
    "    def forward(self, x_enc, x_dec, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_dec)\n",
    "        return dec_out\n",
    "\n",
    "    def classification(self, x_enc, x_dec):\n",
    "        \n",
    "        x_enc = self.normalize_layers(x_enc, 'norm')\n",
    "\n",
    "        # prompt embeddings\n",
    "        prompt = []\n",
    "        for b in range(x_enc.shape[0]):\n",
    "            prompt_ = (f\"<|start_prompt|>Dataset description: The ECG signal from Lead II, recorded for 10 seconds at a sampling rate of 500 Hz, is provided.\"\n",
    "                       f\"Task description: Determine whether the patient's ECG signal from Lead II is normal (0) or abnormal (1).<|end_prompt|>\")\n",
    "            prompt.append(prompt_)\n",
    "        prompt = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).input_ids\n",
    "        prompt_embeddings = self.llm_model.get_input_embeddings()(prompt)\n",
    "    \n",
    "        # source embeddings\n",
    "        source_embeddings = self.mapping_layer(self.word_embeddings.permute(1, 0)).permute(1, 0)\n",
    "        # patch embeddings & reprogramming layer\n",
    "        x_enc = x_enc.permute(0, 2, 1).contiguous()\n",
    "        enc_out, n_vars = self.patch_embedding(x_enc)\n",
    "        enc_out = self.reprogramming_layer(enc_out, source_embeddings, source_embeddings)\n",
    "\n",
    "        # LLM\n",
    "        llama_enc_out = torch.cat([prompt_embeddings, enc_out], dim=1)\n",
    "        dec_out = self.llm_model(inputs_embeds=llama_enc_out).last_hidden_state\n",
    "        dec_out = dec_out[:, :, :self.d_ff] # 이 부분이 필요할까\n",
    "\n",
    "        dec_out = torch.reshape(\n",
    "            dec_out, (-1, n_vars, dec_out.shape[-2], dec_out.shape[-1]))\n",
    "        dec_out = dec_out.permute(0, 1, 3, 2).contiguous()\n",
    "\n",
    "        dec_out = self.output_projection(dec_out[:, :, :, -self.patch_nums:])\n",
    "        dec_out = dec_out.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        return dec_out # (batch_size X class X 변량)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ef68595-bfc1-4d1e-8b00-69ccd6e8d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329cd64240764c3a9888d7afd86f4db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from layers.Embed import PatchEmbedding\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51642f65-8a24-4a13-85df-ce6e3f8bc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbf1a8-0071-4d6d-a387-6157d07cfad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07398323694864908\n",
      "150 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "225 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "300 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "375 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "450 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n",
      "525 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "600 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n",
      "675 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "750 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "825 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "900 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.04158883094787598\n",
      "975 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "1050 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.03696784973144531\n",
      "1125 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "1200 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.04620981216430664\n",
      "1275 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "1350 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "1425 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n",
      "1500 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "1575 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "1650 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "1725 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "1800 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "1875 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "1950 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "2025 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "2100 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "2175 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.09241962432861328\n",
      "2250 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.10628256797790528\n",
      "2325 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "2400 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "2475 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "2550 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.04158883094787598\n",
      "2625 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "2700 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "2775 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "2850 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.04620981216430664\n",
      "2925 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "3000 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "3075 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "3150 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "3225 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "3300 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "3375 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "3450 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "3525 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.09241962432861328\n",
      "3600 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "3675 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "3750 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "3825 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "3900 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "3975 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "4050 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "4125 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "4200 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "4275 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06931471824645996\n",
      "4350 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "4425 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n",
      "4500 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "4575 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08779864311218262\n",
      "4650 tensor([0.5000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.04620981216430664\n",
      "4725 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.09704060554504394\n",
      "4800 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "4875 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "4950 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.1016615867614746\n",
      "5025 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "5100 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "5175 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "5250 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.03696784973144531\n",
      "5325 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "5400 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n",
      "5475 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "5550 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "5625 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "5700 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "5775 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "5850 tensor([0.0000, 0.5000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "5925 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0646937370300293\n",
      "6000 tensor([0.5000, 1.0000], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "6075 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.06007275581359863\n",
      "6150 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07393569946289062\n",
      "6225 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.07855668067932128\n",
      "6300 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "6375 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.09704060554504394\n",
      "6450 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.05545177459716797\n",
      "6525 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "6600 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.08317766189575196\n",
      "6675 tensor([0., 1.], grad_fn=<SqueezeBackward0>) tensor([0., 1.]) 0.0508307933807373\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for epoch in range(1):\n",
    "    train_loss = []\n",
    "    tmp = []\n",
    "    \n",
    "    model.train()\n",
    "    for i, (batch_x, batch_y) in enumerate(data_loader):\n",
    "        batch_x = batch_x.float()\n",
    "        batch_y = batch_y.float()\n",
    "        \n",
    "        outputs = model(batch_x.squeeze(0), batch_y.squeeze())\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), batch_y.squeeze())\n",
    "        \n",
    "        if i % 75 == 0 and tmp:\n",
    "            print(i, outputs.squeeze(), batch_y.squeeze(), sum(tmp)/len(tmp))\n",
    "            train_loss.append(float(sum(tmp)/len(tmp)))\n",
    "            tmp = []\n",
    "            \n",
    "        tmp.append(float(loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch} | Train Loss: {sum(train_loss)/len(train_loss):.7f}')\n",
    "    plt.plot(train_loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6ec42-2148-4c6f-a381-02d2efc95c9e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1e1db1-b7a7-4375-9d0c-f6c175c1a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fca1f7f3cf44aebb090931f1d0728f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import LlamaConfig, LlamaModel, LlamaTokenizer\n",
    "\n",
    "llama_config = LlamaConfig.from_pretrained('huggyllama/llama-7b')\n",
    "llama_config.num_hidden_layers = 32 # d_model\n",
    "llama_config.output_attentions = True\n",
    "llama_config.output_hidden_states = True\n",
    "\n",
    "llm_model = LlamaModel.from_pretrained(\n",
    "                    # \"/mnt/alps/modelhub/pretrained_model/LLaMA/7B_hf/\",\n",
    "                    'huggyllama/llama-7b',\n",
    "                    trust_remote_code=True,\n",
    "                    local_files_only=True,\n",
    "                    config=llama_config,\n",
    "                    # load_in_4bit=True\n",
    "                )\n",
    "\n",
    "for param in llm_model.parameters(): # LLM 파라미터 고정\n",
    "    param.requires_grad = False\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "                    'huggyllama/llama-7b',\n",
    "                    trust_remote_code=True,\n",
    "                    local_files_only=True\n",
    "                )\n",
    "\n",
    "if tokenizer.eos_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "else:\n",
    "    pad_token = '[PAD]'\n",
    "    tokenizer.add_special_tokens({'pad_token': pad_token})\n",
    "    tokenizer.pad_token = pad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4d333-2648-42f1-b9fe-5e17425a2984",
   "metadata": {},
   "source": [
    "# Prompt Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86e6a664-35f5-4338-9f6d-1b90820dc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ = (f\"<|start_prompt|>Dataset description: The ECG signal from Lead II, recorded for 10 seconds at a sampling rate of 500 Hz, is provided.\"\n",
    "           f\"Task description: Determine whether the patient's ECG signal from Lead II is normal (0) or abnormal (1).<|end_prompt|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0301bc8e-9259-4ef3-8a46-ecf184dbb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = []\n",
    "for b in range(batch_x.shape[0]):\n",
    "    prompt.append(prompt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e42725a4-fee8-4fc3-88d0-8f62e7abfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e38c5171-8da4-4b5c-97ee-64247868cf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ea4fb0-7596-4a53-9fda-744345fa9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_embeddings = llm_model.get_input_embeddings()(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70be2fe6-e08b-47f4-b7a0-e96371bdbbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 4096])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2305d-19cd-49ba-9627-efa575b11e24",
   "metadata": {},
   "source": [
    "# Reprogramming_layer\n",
    "1. source embedding\n",
    "2. patch embedding -> enc_out\n",
    "3. 1과 2를 attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bf0fb3-43e9-4b51-a703-8deba989188a",
   "metadata": {},
   "source": [
    "## source embedding & patch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "149177ee-1a5d-48d5-86a4-6bad161d60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from layers.Embed import PatchEmbedding\n",
    "\n",
    "patch_embedding = PatchEmbedding(32, 156, 78, 0.1)\n",
    "\n",
    "word_embeddings = llm_model.get_input_embeddings().weight\n",
    "\n",
    "vocab_size = word_embeddings.shape[0]\n",
    "num_tokens = 1000\n",
    "mapping_layer = nn.Linear(vocab_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1477491c-f89e-4352-b954-743fb87439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_embeddings = mapping_layer(word_embeddings.permute(1, 0)).permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "039322be-f54e-466c-bb81-3086fde3f4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4096])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33fdc3d9-9e25-49f1-86d0-83b3d71bbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = batch_x.permute(0, 2, 1).contiguous()\n",
    "enc_out, n_vars = patch_embedding(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb61a3e1-822a-4346-a584-823575ea517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 32])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(enc_out.shape) # 패치 길이를 156으로 바꿔서 -> 패치 개수 64개\n",
    "print(n_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a79def-b650-4459-80bb-2e613c71c78c",
   "metadata": {},
   "source": [
    "## reprogramming layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64808653-503a-41c5-9982-a173ee7da0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class ReprogrammingLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_keys=None, d_llm=None, attention_dropout=0.1):\n",
    "        super(ReprogrammingLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.out_projection = nn.Linear(d_keys * n_heads, d_llm)\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, _ = target_embedding.shape # 임베딩 차원 생략\n",
    "        S, _ = source_embedding.shape # 임베딩 차원 생략\n",
    "        H = self.n_heads\n",
    "\n",
    "        target_embedding = self.query_projection(target_embedding).view(B, L, H, -1)\n",
    "        source_embedding = self.key_projection(source_embedding).view(S, H, -1)\n",
    "        value_embedding = self.value_projection(value_embedding).view(S, H, -1)\n",
    "\n",
    "        out = self.reprogramming(target_embedding, source_embedding, value_embedding)\n",
    "\n",
    "        out = out.reshape(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out)\n",
    "\n",
    "    def reprogramming(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, H, E = target_embedding.shape\n",
    "\n",
    "        scale = 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,she->bhls\", target_embedding, source_embedding)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        reprogramming_embedding = torch.einsum(\"bhls,she->blhe\", A, value_embedding)\n",
    "\n",
    "        return reprogramming_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "312b3312-7b14-4059-a727-3a09713d1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprogramming_layer = ReprogrammingLayer(32, 8, 128, 4096) # n_head, d_ff 뭘로 하지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c99a3d53-7623-41ff-95b6-673a69f3df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out = reprogramming_layer(enc_out, source_embeddings, source_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48ed217e-72c8-451e-b794-5556ee494042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 4096])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e9b371c-6a4d-45fc-a70c-be80a5eef112",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_enc_out = torch.cat([prompt_embeddings, enc_out], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aea11c66-eb3d-4aa7-bd5d-b5d1d168b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 144, 4096])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_enc_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6694ae6-2b3c-4f5c-9d9a-88a4979fcb98",
   "metadata": {},
   "source": [
    "# LLM 모델에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cd0eba2-e02d-4c58-a2a3-eeae697a1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out = llm_model(inputs_embeds=llama_enc_out).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40052392-e459-4b1c-8dea-7a2f13298ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 144, 4096])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b459bc43-b783-4af5-8dec-e21e00a83d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out = dec_out[:, :, :128] # d_ff까지만 보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80b57cbf-e469-45ce-8222-3780b0f357b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out = torch.reshape(\n",
    "            dec_out, (-1, n_vars, dec_out.shape[-2], dec_out.shape[-1]))\n",
    "dec_out = dec_out.permute(0, 1, 3, 2).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "678d421c-b3ca-426d-88b7-98f970cab0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 144])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed554dc-61db-4215-a04f-9af038b8771b",
   "metadata": {},
   "source": [
    "# 확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "baa258a9-18f9-4688-89fc-b3d6933592d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Sequential(\n",
    "                        nn.Linear(nf, 512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(512, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, target_window)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "output_projection = FlattenHead(1, 128*144, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3874fc76-6ada-4ed3-bd44-b9e242168db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out = output_projection(dec_out[:, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7599958b-c01b-4904-8926-a3d7136eee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4693, 0.4217]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7e101be1-d76c-4024-8852-dfed6f9fe829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4693],\n",
       "         [0.4217]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.permute(0, 2, 1).contiguous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timellm",
   "language": "python",
   "name": "timellm_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
