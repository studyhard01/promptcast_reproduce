{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46daaef8-6e20-4d31-ae9b-7f0bd6d21ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.28.0\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops==0.7.0\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.7.0\n",
      "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.5.3\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit_learn==1.2.2\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scipy==1.12.0\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.65.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft==0.4.0\n",
      "  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.31.0\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting deepspeed==0.14.0\n",
      "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece==0.2.0\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.1.4)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.3)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (1.11.1)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from accelerate==0.28.0->-r requirements.txt (line 2)) (6.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (4.54.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 6)) (2022.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2.32.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hjson\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pynvml\n",
      "  Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 1)) (2.1.5)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.2->-r requirements.txt (line 1)) (1.2.1)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400407 sha256=b072ac2426b2684f4a5ff4e4c7568a1a8423440e367c2d380a214b0d313379d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/b2/55/5e042f066de2f921ceb258c4c2f99cad4d7ac5947f9f99d814\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: tokenizers, sentencepiece, py-cpuinfo, ninja, hjson, typing-extensions, triton, tqdm, threadpoolctl, safetensors, regex, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, joblib, fsspec, einops, annotated-types, scipy, pydantic-core, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, transformers, scikit_learn, pydantic, nvidia-cusolver-cu12, matplotlib, torch, deepspeed, accelerate, peft\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.9.2\n",
      "    Uninstalling matplotlib-3.9.2:\n",
      "      Successfully uninstalled matplotlib-3.9.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "Successfully installed accelerate-0.28.0 annotated-types-0.7.0 deepspeed-0.14.0 einops-0.7.0 fsspec-2024.9.0 hjson-3.1.0 huggingface-hub-0.25.1 joblib-1.4.2 matplotlib-3.7.0 ninja-1.11.1.1 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 peft-0.4.0 py-cpuinfo-9.0.0 pydantic-2.9.2 pydantic-core-2.23.4 pynvml-11.5.3 regex-2024.9.11 safetensors-0.4.5 scikit_learn-1.2.2 scipy-1.12.0 sentencepiece-0.2.0 threadpoolctl-3.5.0 tokenizers-0.13.3 torch-2.2.2 tqdm-4.65.0 transformers-4.31.0 triton-2.2.0 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbb6bb8-7f99-4940-a154-7ec0a11c041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-09-27 04:46:22,586] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,602] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,602] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,603] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,603] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,711] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,797] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:22,902] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:23,831] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:23,831] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-09-27 04:46:23,831] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:23,872] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "[2024-09-27 04:46:23,911] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:23,911] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 126, in <module>\n",
      "    train_data, train_loader = data_provider(args, 'train')\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_factory.py\", line 46, in data_provider\n",
      "    data_set = Data(\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 41, in __init__\n",
      "    self.__read_data__()\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 48, in __read_data__\n",
      "    df_raw = pd.read_csv(os.path.join(self.root_path,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/common.py\", line 856, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/ETT-small/ETTh1.csv'\n",
      "[2024-09-27 04:46:23,935] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "    \n",
      "accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[2024-09-27 04:46:23,992] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[2024-09-27 04:46:24,067] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 126, in <module>\n",
      "    train_data, train_loader = data_provider(args, 'train')\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_factory.py\", line 46, in data_provider\n",
      "    data_set = Data(\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 41, in __init__\n",
      "    self.__read_data__()\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 48, in __read_data__\n",
      "    df_raw = pd.read_csv(os.path.join(self.root_path,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/common.py\", line 856, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/ETT-small/ETTh1.csv'\n",
      "[2024-09-27 04:46:28,419] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3321) of binary: /opt/conda/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1048, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 702, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "run_main.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 3322)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 3323)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 3324)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[4]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 4 (local_rank: 4)\n",
      "  exitcode  : 1 (pid: 3325)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[5]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 5 (local_rank: 5)\n",
      "  exitcode  : 1 (pid: 3326)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[6]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 6 (local_rank: 6)\n",
      "  exitcode  : 1 (pid: 3327)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[7]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 7 (local_rank: 7)\n",
      "  exitcode  : 1 (pid: 3328)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-09-27_04:46:28\n",
      "  host      : b7b08726c3b3\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 3321)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-09-27 04:46:34,929] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:34,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:34,966] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:34,966] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:34,966] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:34,968] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:35,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:35,160] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-27 04:46:36,139] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:36,141] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[2024-09-27 04:46:36,190] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:36,197] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[2024-09-27 04:46:36,243] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:36,243] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-09-27 04:46:36,248] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-27 04:46:36,271] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[2024-09-27 04:46:36,316] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 126, in <module>\n",
      "    train_data, train_loader = data_provider(args, 'train')\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_factory.py\", line 46, in data_provider\n",
      "    data_set = Data(\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 41, in __init__\n",
      "    self.__read_data__()\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 48, in __read_data__\n",
      "    df_raw = pd.read_csv(os.path.join(self.root_path,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/common.py\", line 856, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/ETT-small/ETTh1.csv'\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 104, in <module>\n",
      "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 371, in __init__\n",
      "    self.state = AcceleratorState(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 777, in __init__\n",
      "    PartialState(cpu, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 211, in __init__\n",
      "    torch.cuda.set_device(self.device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 408, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/hsh/Time-LLM/run_main.py\", line 126, in <module>\n",
      "    train_data, train_loader = data_provider(args, 'train')\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_factory.py\", line 46, in data_provider\n",
      "    data_set = Data(\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 41, in __init__\n",
      "    self.__read_data__()\n",
      "  File \"/tf/hsh/Time-LLM/data_provider/data_loader.py\", line 48, in __read_data__\n",
      "    df_raw = pd.read_csv(os.path.join(self.root_path,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pandas/io/common.py\", line 856, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/ETT-small/ETTh1.csv'\n",
      "^C\n",
      "[2024-09-27 04:46:38,455] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
      "[2024-09-27 04:46:38,456] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3468 closing signal SIGINT\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/TimeLLM_ETTh1.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
